import numpy as np



# Features: [keyword_freq, sender_score, email_length]

X = np.array([
    [0.9, 0.1, 0.3],  # Likely spam
    [0.1, 0.9, 0.5],  # Likely not spam
    [0.8, 0.2, 0.4],  # Likely spam
    [0.2, 0.8, 0.6],  # Likely not spam
    [0.7, 0.1, 0.2],  # Likely spam
    [0.1, 0.95, 0.5]  # Likely not spam
])

# Labels: 1 = Spam, 0 = Not Spam
Y = np.array([[1], [0], [1], [0], [1], [0]])


np.random.seed(42)
W = np.random.rand(3, 1)     # 3 input features
b = np.random.rand(1)
lr = 0.1
epochs = 1000

def sigmoid(x):
    return 1 / (1 + np.exp(-x))

def cross_entropy_loss(y_true, y_pred):
    eps = 1e-15
    y_pred = np.clip(y_pred, eps, 1 - eps)
    return -np.mean(y_true * np.log(y_pred) + (1 - y_true) * np.log(1 - y_pred))


for epoch in range(epochs):
    z = np.dot(X, W) + b         # Linear model
    A = sigmoid(z)               # Activation

    # Loss and gradient
    loss = cross_entropy_loss(Y, A)
    d_loss = A - Y               # Gradient of loss w.r.t z

    # Backpropagation
    dW = np.dot(X.T, d_loss)
    db = np.sum(d_loss)

    # Update weights and bias
    W -= lr * dW
    b -= lr * db

    # Log every 100 epochs
    if epoch % 100 == 0:
        print(f"Epoch {epoch}, Loss: {loss:.4f}")


output = sigmoid(np.dot(X, W) + b)
print("\nFinal Predictions (0 = Not Spam, 1 = Spam):")
print(output.round())
